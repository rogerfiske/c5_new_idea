### Similar Datasets in Quantum Computing

The C5_Matrix_Binary dataset features sequential events with sparse binary vectors in a 39-dimensional space, where exactly 5 positions are active (1s) per event, representing quantum vector activations for multi-target binary classification tasks. While exact matches are rare due to the dataset's specific constraints (e.g., uniform sparsity and low correlations), several open datasets in quantum computing share similarities in structure: sparse binary or binary-like representations of qubit states/activations, low-to-moderate dimensionality, sequential or time-evolved data, and applications in machine learning (ML) for prediction or classification. These often arise from qubit simulations, Pauli basis decompositions, or circuit optimizations, emphasizing sparsity for efficient quantum encoding.

Below is a curated list of the most relevant datasets, prioritized by similarity to C5's sparsity (e.g., binary activations in vectors/matrices) and sequential nature. I focused on publicly available, high-quality sources from quantum ML benchmarks.

| Dataset Name | Source & Access | Key Structure & Dimensions | Sparsity & Binary Aspects | Size & Sequential Elements | ML Tasks & Similarity to C5 |
|--------------|-----------------|----------------------------|---------------------------|----------------------------|-----------------------------|
| **QDataSet** | GitHub (eperrier/QDataSet); arXiv:2108.06661 | Pauli operator matrices (2x2 for 1-qubit, 4x4 for 2-qubit); expectation value vectors (3 scalars per state for Pauli X/Y/Z measurements); Hamiltonians/unitaries as tensor products. | Sparse Pauli matrices with binary-like ±1 eigenvalues/off-diagonals; expectation vectors sparse (only 3 active values per state, bounded [-1,1]); noise realizations as sparse perturbations. | 52 datasets, 10,000 samples each; sequential over M=1024 time steps with K=2000 Monte Carlo noise realizations per sample. Total ~14TB compressed. | Quantum state tomography, control prediction, noise classification; high similarity—sparse "activations" of qubit observables in low-D space, uniform distributions, for multi-target prediction (e.g., next-state expectations). Extensible to higher qubits. |
| **VQE-Generated Quantum Circuit Dataset** | arXiv:2302.09751; GitHub (implied via paper); Phys. Rev. X (2025) | Optimized quantum circuits as parameter sets (ansatz coefficients) for VQE on condensed-matter Hamiltonians; circuit graphs or binary gate sequences. | Sparse circuit representations (e.g., binary indicators for gate activations); parameters can be binarized for sparse vectors encoding state preparations. | ~10,000 circuits, up to 20 qubits; sequential in optimization iterations (VQE convergence steps). | Circuit clustering/classification; medium similarity—sparse binary-like encodings of qubit interactions/states for generative ML, akin to predicting active QVs; designed for QML where classical baselines fail. |
| **QM7 (Quantum-Machine.org Benchmark)** | quantum-machine.org/datasets | Coulomb matrices (23x23 symmetric) for molecular properties; derived from quantum states. | Sparse off-diagonal elements in matrices; binary-like for atomic interactions in sparse graphs. | 7,211 molecules; no explicit sequencing, but time-independent quantum snapshots. | Molecular property prediction (regression/classification); low-medium similarity—sparse matrix reps of quantum states, but denser than C5; useful for benchmarking sparse quantum ML. |
| **Sparse Statevector Conversion Benchmarks** | arXiv:2407.15745 (no dedicated repo, but code/examples available) | Sparse statevectors (r non-zero amplitudes out of 2^n basis states) for qubit encoding; e.g., r=10-1000 in n=10-30 qubits. | Highly sparse binary/complex vectors (only r active positions); focuses on qubit activation patterns. | Variable: 1,000-1M samples simulated; sequential loading steps for time-series data encoding. | Quantum data loading for ML/signal processing; high similarity—explicit sparse binary vectors for qubit activations, with fixed sparsity ratios (e.g., r/2^n ~5/39), for prediction tasks like next-state evolution. |
| **PennyLane Conventional Datasets for QML** | pennylane.ai/datasets/conventional-datasets-for-qml | Adapted classical datasets (e.g., Iris, MNIST) encoded as quantum states (amplitude/basis encodings); qubit feature maps. | Basis encoding: binary one-hot vectors for categories; amplitude: sparse complex vectors on 2^n states. | Varies (e.g., 150 samples for Iris on 4-8 qubits); sequential for time-series variants like stock prices. | Quantum classification/regression; medium similarity—binary sparse encodings of states, but classical-to-quantum hybrids; supports multi-label tasks like C5's least-likely prediction. |

These datasets are primarily simulation-based, reflecting the nascent stage of real quantum hardware data collection. QDataSet stands out for its scale and direct focus on sparse qubit activations in noisy, sequential environments, making it the closest analog for extending C5-style models (e.g., LSTM for time-evolution prediction). For implementation, most integrate with libraries like Qiskit or PennyLane. If you need code to load/explore one (e.g., via the code_execution tool), or deeper dives into specifics, let me know!