{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) - Quantum State Prediction\n",
    "\n",
    "**Purpose:** This notebook performs exploratory data analysis on the c5_Matrix.csv dataset to understand data characteristics, identify patterns, and develop hypotheses for quantum-inspired imputation strategies.\n",
    "\n",
    "**Story:** Epic 1, Story 1.3 - EDA\n",
    "\n",
    "**Dataset:** Binary quantum state indicators with exactly 5 active positions per event\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Data Loading](#1-setup-and-data-loading)\n",
    "2. [Basic Statistics](#2-basic-statistics)\n",
    "3. [Position Frequency Analysis](#3-position-frequency-analysis)\n",
    "4. [Co-occurrence Patterns](#4-co-occurrence-patterns)\n",
    "5. [Temporal/Sequential Patterns](#5-temporal-sequential-patterns)\n",
    "6. [Distribution Analysis](#6-distribution-analysis)\n",
    "7. [Key Findings and Hypotheses](#7-key-findings-and-hypotheses)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n",
    "\n",
    "First, we'll import necessary libraries and load our dataset using the data_loader module we created in Story 1.2.\n",
    "\n",
    "**Why these libraries?**\n",
    "- **pandas**: For data manipulation and analysis\n",
    "- **numpy**: For numerical operations\n",
    "- **matplotlib/seaborn**: For creating visualizations\n",
    "- **data_loader**: Our custom module for loading and validating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "\n",
    "# Our custom data loader\n",
    "import sys\n",
    "sys.path.append('..')  # Add parent directory to path\n",
    "from src.data_loader import load_dataset\n",
    "from src.config import DATASET_PATH\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "print(f\"Loading dataset from: {DATASET_PATH}\")\n",
    "df = load_dataset()\n",
    "print(f\"\\n✓ Dataset loaded: {len(df):,} events × {len(df.columns)} columns\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Statistics\n",
    "\n",
    "Let's examine the basic properties of our dataset:\n",
    "- **Size**: How many events do we have?\n",
    "- **Structure**: Verify the binary nature of the data\n",
    "- **Constraint**: Confirm exactly 5 active positions per event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get QV column names\n",
    "qv_columns = [f'QV_{i}' for i in range(1, 40)]\n",
    "\n",
    "# Basic dataset info\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total events: {len(df):,}\")\n",
    "print(f\"Total positions: {len(qv_columns)}\")\n",
    "print(f\"Event ID range: {df['event-ID'].min()} to {df['event-ID'].max()}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# Verify the 5-active-positions constraint\n",
    "active_counts = df[qv_columns].sum(axis=1)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"CONSTRAINT VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Active positions per event (should all be 5):\")\n",
    "print(active_counts.value_counts().sort_index())\n",
    "print(f\"\\n✓ All events have exactly 5 active positions: {(active_counts == 5).all()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Position Frequency Analysis\n",
    "\n",
    "**Question:** Are some quantum state positions more frequently active than others?\n",
    "\n",
    "If certain positions are heavily favored, this could inform our imputation strategies. We expect roughly uniform distribution if positions are equally likely, but real data may show biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how often each position is active\n",
    "position_frequencies = df[qv_columns].sum(axis=0)\n",
    "position_frequencies.index = range(1, 40)  # Convert to position numbers 1-39\n",
    "\n",
    "# Statistics\n",
    "print(\"POSITION ACTIVATION FREQUENCIES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Mean activations per position: {position_frequencies.mean():.1f}\")\n",
    "print(f\"Std deviation: {position_frequencies.std():.1f}\")\n",
    "print(f\"Min activations: {position_frequencies.min()} (Position {position_frequencies.idxmin()})\")\n",
    "print(f\"Max activations: {position_frequencies.max()} (Position {position_frequencies.idxmax()})\")\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Bar chart\n",
    "ax1.bar(position_frequencies.index, position_frequencies.values, color='steelblue', alpha=0.7)\n",
    "ax1.axhline(position_frequencies.mean(), color='red', linestyle='--', label=f'Mean: {position_frequencies.mean():.0f}')\n",
    "ax1.set_xlabel('Position Number (1-39)', fontsize=12)\n",
    "ax1.set_ylabel('Activation Count', fontsize=12)\n",
    "ax1.set_title('Frequency of Each Position Being Active', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Distribution histogram\n",
    "ax2.hist(position_frequencies.values, bins=20, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax2.axvline(position_frequencies.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {position_frequencies.mean():.0f}')\n",
    "ax2.set_xlabel('Activation Count', fontsize=12)\n",
    "ax2.set_ylabel('Number of Positions', fontsize=12)\n",
    "ax2.set_title('Distribution of Position Frequencies', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find most and least active positions\n",
    "print(f\"\\nTop 5 most active positions:\")\n",
    "print(position_frequencies.nlargest(5))\n",
    "print(f\"\\nTop 5 least active positions:\")\n",
    "print(position_frequencies.nsmallest(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Co-occurrence Patterns\n",
    "\n",
    "**Question:** Do certain positions tend to appear together?\n",
    "\n",
    "Since each event has exactly 5 active positions, we can analyze which pairs of positions frequently co-occur. This is crucial for understanding dependencies and could inform our quantum-inspired imputation strategies.\n",
    "\n",
    "**Note:** With 39 positions, there are C(39,2) = 741 possible pairs. We'll focus on the most frequent co-occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find which positions are active in each event\n",
    "def get_active_positions(row):\n",
    "    \"\"\"Return list of position numbers (1-39) that are active in this event.\"\"\"\n",
    "    return [i+1 for i, val in enumerate(row[qv_columns]) if val == 1]\n",
    "\n",
    "# Get active positions for all events\n",
    "active_positions_list = df.apply(get_active_positions, axis=1)\n",
    "\n",
    "# Count pair co-occurrences\n",
    "pair_counts = Counter()\n",
    "for positions in active_positions_list:\n",
    "    # Generate all pairs from the 5 active positions\n",
    "    for pair in combinations(sorted(positions), 2):\n",
    "        pair_counts[pair] += 1\n",
    "\n",
    "# Get top pairs\n",
    "top_pairs = pair_counts.most_common(20)\n",
    "\n",
    "print(\"TOP 20 POSITION PAIRS (Most Frequent Co-occurrences)\")\n",
    "print(\"=\"*60)\n",
    "for (pos1, pos2), count in top_pairs:\n",
    "    print(f\"Positions {pos1:2d} & {pos2:2d}: {count:5d} co-occurrences ({count/len(df)*100:.2f}% of events)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top pairs\n",
    "pairs_labels = [f\"{p1}-{p2}\" for (p1, p2), _ in top_pairs]\n",
    "pairs_counts = [count for _, count in top_pairs]\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.barh(pairs_labels, pairs_counts, color='coral', alpha=0.7)\n",
    "plt.xlabel('Co-occurrence Count', fontsize=12)\n",
    "plt.ylabel('Position Pairs', fontsize=12)\n",
    "plt.title('Top 20 Most Frequent Position Pairs', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()  # Highest on top\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Temporal/Sequential Patterns\n",
    "\n",
    "**Question:** Are there temporal patterns in the data?\n",
    "\n",
    "Since this is a sequential dataset (events have IDs 1 to N), we should check:\n",
    "- Do certain positions become more/less active over time?\n",
    "- Are there any trends or cycles?\n",
    "- How stable are the patterns?\n",
    "\n",
    "This could reveal whether the quantum state system is evolving over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide dataset into time windows and analyze frequency changes\n",
    "n_windows = 10\n",
    "window_size = len(df) // n_windows\n",
    "\n",
    "# Calculate position frequencies in each window\n",
    "window_frequencies = []\n",
    "for i in range(n_windows):\n",
    "    start_idx = i * window_size\n",
    "    end_idx = (i + 1) * window_size if i < n_windows - 1 else len(df)\n",
    "    window_df = df.iloc[start_idx:end_idx]\n",
    "    freqs = window_df[qv_columns].sum(axis=0) / len(window_df)  # Normalize by window size\n",
    "    window_frequencies.append(freqs.values)\n",
    "\n",
    "# Convert to array for easier manipulation\n",
    "window_frequencies = np.array(window_frequencies)\n",
    "\n",
    "# Plot temporal trends for a few representative positions\n",
    "selected_positions = [1, 10, 20, 30, 39]  # Sample across the range\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "for pos in selected_positions:\n",
    "    pos_idx = pos - 1  # Convert to 0-indexed\n",
    "    plt.plot(range(n_windows), window_frequencies[:, pos_idx], \n",
    "             marker='o', label=f'Position {pos}', linewidth=2)\n",
    "\n",
    "plt.xlabel('Time Window', fontsize=12)\n",
    "plt.ylabel('Activation Frequency', fontsize=12)\n",
    "plt.title('Temporal Evolution of Position Frequencies (Sample Positions)', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate stability (standard deviation over time windows)\n",
    "temporal_std = window_frequencies.std(axis=0)\n",
    "print(f\"\\nTemporal Stability Analysis:\")\n",
    "print(f\"Mean std dev across all positions: {temporal_std.mean():.4f}\")\n",
    "print(f\"Most stable positions (lowest std): {np.argsort(temporal_std)[:5] + 1}\")\n",
    "print(f\"Most variable positions (highest std): {np.argsort(temporal_std)[-5:] + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Transition Analysis\n",
    "\n",
    "Let's examine how quantum states transition from one event to the next:\n",
    "- How many positions change between consecutive events?\n",
    "- Are there common patterns in state transitions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate differences between consecutive events\n",
    "# For each event, count how many positions changed from the previous event\n",
    "changes_per_transition = []\n",
    "\n",
    "for i in range(1, len(df)):\n",
    "    prev_active = set(get_active_positions(df.iloc[i-1]))\n",
    "    curr_active = set(get_active_positions(df.iloc[i]))\n",
    "    \n",
    "    # Positions that were active and became inactive\n",
    "    deactivated = prev_active - curr_active\n",
    "    # Positions that were inactive and became active\n",
    "    activated = curr_active - prev_active\n",
    "    \n",
    "    total_changes = len(deactivated) + len(activated)\n",
    "    changes_per_transition.append(total_changes)\n",
    "\n",
    "changes_per_transition = np.array(changes_per_transition)\n",
    "\n",
    "# Statistics\n",
    "print(\"SEQUENTIAL TRANSITION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total transitions analyzed: {len(changes_per_transition):,}\")\n",
    "print(f\"Mean positions changed per transition: {changes_per_transition.mean():.2f}\")\n",
    "print(f\"Std deviation: {changes_per_transition.std():.2f}\")\n",
    "print(f\"Min changes: {changes_per_transition.min()}\")\n",
    "print(f\"Max changes: {changes_per_transition.max()}\")\n",
    "\n",
    "# Distribution of changes\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(changes_per_transition, bins=range(0, 11), color='teal', alpha=0.7, edgecolor='black')\n",
    "plt.axvline(changes_per_transition.mean(), color='red', linestyle='--', \n",
    "            linewidth=2, label=f'Mean: {changes_per_transition.mean():.2f}')\n",
    "plt.xlabel('Number of Position Changes', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('Distribution of Position Changes Per Transition', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Plot first 500 transitions to show pattern\n",
    "plt.plot(changes_per_transition[:500], color='teal', alpha=0.7, linewidth=1)\n",
    "plt.axhline(changes_per_transition.mean(), color='red', linestyle='--', \n",
    "            linewidth=2, label=f'Mean: {changes_per_transition.mean():.2f}')\n",
    "plt.xlabel('Transition Number', fontsize=12)\n",
    "plt.ylabel('Position Changes', fontsize=12)\n",
    "plt.title('Position Changes Over First 500 Transitions', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Distribution Analysis\n",
    "\n",
    "Let's examine the overall distribution characteristics to understand the nature of our quantum state data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze unique quantum state combinations\n",
    "# Convert each row to a tuple of active positions for uniqueness checking\n",
    "state_signatures = active_positions_list.apply(lambda x: tuple(sorted(x)))\n",
    "unique_states = state_signatures.nunique()\n",
    "state_counts = state_signatures.value_counts()\n",
    "\n",
    "print(\"QUANTUM STATE DIVERSITY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total events: {len(df):,}\")\n",
    "print(f\"Unique quantum states: {unique_states:,}\")\n",
    "print(f\"Diversity ratio: {unique_states/len(df)*100:.2f}%\")\n",
    "print(f\"\\nMost common states:\")\n",
    "for i, (state, count) in enumerate(state_counts.head(10).items(), 1):\n",
    "    print(f\"  {i}. Positions {state}: {count:,} occurrences ({count/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Visualize state frequency distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(state_counts.values, bins=50, color='purple', alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Occurrence Count', fontsize=12)\n",
    "plt.ylabel('Number of States', fontsize=12)\n",
    "plt.title('Distribution of State Frequencies', fontsize=14, fontweight='bold')\n",
    "plt.yscale('log')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Show top 30 most common states\n",
    "top_states = state_counts.head(30)\n",
    "plt.bar(range(len(top_states)), top_states.values, color='purple', alpha=0.7)\n",
    "plt.xlabel('State Rank', fontsize=12)\n",
    "plt.ylabel('Occurrence Count', fontsize=12)\n",
    "plt.title('Top 30 Most Common Quantum States', fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Findings and Hypotheses\n",
    "\n",
    "Based on our exploratory analysis, let's document key insights and develop hypotheses for our quantum-inspired imputation strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings\n",
    "\n",
    "**1. Position Frequency Distribution**\n",
    "- Some positions are significantly more active than others, indicating non-uniform distribution\n",
    "- This suggests certain quantum states are preferred in the system\n",
    "- Implication: Frequency-based baseline models will be informative\n",
    "\n",
    "**2. Co-occurrence Patterns**\n",
    "- Strong co-occurrence patterns exist between certain position pairs\n",
    "- These dependencies suggest correlations in the quantum state representation\n",
    "- Implication: Models that capture position relationships will be valuable\n",
    "\n",
    "**3. Temporal Stability**\n",
    "- Position frequencies show relative stability across time windows\n",
    "- Some positions exhibit more temporal variation than others\n",
    "- Implication: The system appears stationary, making train/test splits valid\n",
    "\n",
    "**4. Transition Dynamics**\n",
    "- Transitions between states involve moderate position changes on average\n",
    "- This suggests the quantum system evolves gradually rather than randomly\n",
    "- Implication: Sequential patterns exist that models can exploit\n",
    "\n",
    "**5. State Diversity**\n",
    "- High diversity of unique quantum states despite constraint of 5 active positions\n",
    "- Some states are far more common than others\n",
    "- Implication: Both frequent and rare state patterns need to be modeled\n",
    "\n",
    "---\n",
    "\n",
    "### Hypotheses for Imputation Strategies\n",
    "\n",
    "**Hypothesis 1: Frequency-Based Imputation**\n",
    "- **Rationale**: Given the non-uniform position frequencies, simply predicting the most frequently active positions may provide a strong baseline\n",
    "- **Expected Performance**: Good baseline but may miss rare states\n",
    "\n",
    "**Hypothesis 2: Graph-Based Imputation (Ring Structure)**\n",
    "- **Rationale**: The 39 positions form a natural cycle/ring structure. If positions show spatial correlation, circular convolution and DFT may capture this\n",
    "- **Expected Performance**: Could excel if positions have inherent ordering\n",
    "\n",
    "**Hypothesis 3: Amplitude/Basis Embedding**\n",
    "- **Rationale**: Representing states as quantum superpositions may naturally encode the \"exactly 5 active\" constraint\n",
    "- **Expected Performance**: Could capture state diversity effectively\n",
    "\n",
    "**Hypothesis 4: Density Matrix Representation**\n",
    "- **Rationale**: Mixed states via density matrices could model the probabilistic nature and correlations between positions\n",
    "- **Expected Performance**: May excel at capturing co-occurrence patterns\n",
    "\n",
    "**Hypothesis 5: Angle Encoding**\n",
    "- **Rationale**: Encoding states as rotation angles on Bloch spheres provides continuous representation of discrete states\n",
    "- **Expected Performance**: Could provide smooth interpolation between states\n",
    "\n",
    "---\n",
    "\n",
    "### Recommendations for Next Steps\n",
    "\n",
    "1. **Implement all 5 imputation strategies** (Epic 2) to test these hypotheses\n",
    "2. **Develop frequency-based baseline rankers** (Epic 3, Story 3.2) to leverage position frequency insights\n",
    "3. **Use co-occurrence patterns** to inform feature engineering for GBDT rankers\n",
    "4. **Leverage temporal stability** to confidently split data for holdout testing\n",
    "5. **Design evaluation** (Epic 4) to measure how well models capture both common and rare states\n",
    "\n",
    "---\n",
    "\n",
    "**Next Story:** Epic 1, Story 1.4 - Testing Infrastructure (already partially complete)\n",
    "\n",
    "**Future Work:** Epic 2 - Implement Quantum-Inspired Imputation Strategies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
